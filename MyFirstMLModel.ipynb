{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model - Linear Regression & Random Forest\n",
    "\n",
    "In this notebook, we will explore a machine learning task using the **Delaney Solubility** dataset. We will create two models: a **Linear Regression** model and a **Random Forest Regressor** model, and evaluate their performance using **Mean Squared Error (MSE)** and **R2 Score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Dataset\n",
    "We will begin by loading the dataset and examining its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   logS  ...  x8  x9  x10\n",
      "0  2.135 ...   1   1   1\n",
      "1  2.710 ...   1   1   1\n",
      "2  2.430 ...   1   1   1\n",
      "3  2.868 ...   1   1   1\n",
      "4  2.885 ...   1   1   1\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/abdulsaboor2/ml-solubility-prediction/refs/heads/main/delaney_solubility_with_descriptors.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing the Data\n",
    "We will separate the target variable `logS` from the feature set and split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target variable (y) and features (X)\n",
    "y = df['logS']\n",
    "X = df.drop('logS', axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "X_train.head(), X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train Linear Regression Model\n",
    "We will train a Linear Regression model and evaluate it using MSE and R2 scores on both training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results:\n",
      "Training MSE: 0.0020801350711187416, Training R2: 0.9996937067928814\n",
      "Test MSE: 0.0034328719382950223, Test R2: 0.999457557679435\n"
     ]
    }
   ],
   "source": [
    "# Train Linear Regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict with Linear Regression\n",
    "y_lr_train_pred = lr.predict(X_train)\n",
    "y_lr_test_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate Linear Regression\n",
    "lr_train_mse = mean_squared_error(y_train, y_lr_train_pred)\n",
    "lr_train_r2 = r2_score(y_train, y_lr_train_pred)\n",
    "lr_test_mse = mean_squared_error(y_test, y_lr_test_pred)\n",
    "lr_test_r2 = r2_score(y_test, y_lr_test_pred)\n",
    "\n",
    "print('Linear Regression Results:')\n",
    "print(f'Training MSE: {lr_train_mse}, Training R2: {lr_train_r2}')\n",
    "print(f'Test MSE: {lr_test_mse}, Test R2: {lr_test_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train Random Forest Model\n",
    "Next, we will train a Random Forest model and evaluate it using the same metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "Training MSE: 0.001481564545573744, Training R2: 0.9997638229002245\n",
      "Test MSE: 0.0035828130466794923, Test R2: 0.9994207415408699\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest model\n",
    "rf = RandomForestRegressor(max_depth=2, random_state=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict with Random Forest\n",
    "y_rf_train_pred = rf.predict(X_train)\n",
    "y_rf_test_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_train_mse = mean_squared_error(y_train, y_rf_train_pred)\n",
    "rf_train_r2 = r2_score(y_train, y_rf_train_pred)\n",
    "rf_test_mse = mean_squared_error(y_test, y_rf_test_pred)\n",
    "rf_test_r2 = r2_score(y_test, y_rf_test_pred)\n",
    "\n",
    "print('Random Forest Results:')\n",
    "print(f'Training MSE: {rf_train_mse}, Training R2: {rf_train_r2}')\n",
    "print(f'Test MSE: {rf_test_mse}, Test R2: {rf_test_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Combine Results and Visualize\n",
    "Finally, we will combine the results of both models and visualize the predictions of the Linear Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results from both models\n",
    "lr_results = pd.DataFrame(['Linear Regression', lr_train_mse, lr_train_r2, lr_test_mse, lr_test_r2]).transpose()\n",
    "rf_results = pd.DataFrame(['Random Forest', rf_train_mse, rf_train_r2, rf_test_mse, rf_test_r2]).transpose()\n",
    "df_models = pd.concat([lr_results, rf_results], axis=0).reset_index(drop=True)\n",
    "print(df_models)\n",
    "\n",
    "# Visualization: Linear Regression predictions\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_train, y_lr_train_pred, c=\"#7CAE00\", alpha=0.3)\n",
    "z = np.polyfit(y_train, y_lr_train_pred, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_train, p(y_train), '#F8766D')\n",
    "plt.ylabel('Predicted LogS')\n",
    "plt.xlabel('Experimental LogS')\n",
    "plt.title('Linear Regression: Experimental vs Predicted LogS')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
